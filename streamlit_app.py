# Handle SQLite for ChromaDB
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except (ImportError, KeyError):
    pass

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import tempfile
import pypandoc
import magic
import PyPDF2
import io
import logging
import streamlit as st
import os

from src.components.llm import get_chat_completion
from src.components.prompts import CLIENT_REQUIREMENTS_PROMPT, INTERVIEW_PROMPT
from src.components.sidebar import render_sidebar
from src.components.researcher import GapAnalysisCrew, StreamToExpander
# from src.components.researcher import create_researcher, create_research_task, run_research
from src.utils.output_handler import capture_output


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

#--------------------------------#
#         Streamlit App          #
#--------------------------------#
# Configure the page
st.set_page_config(
    page_title="CrewAI Research Assistant",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Logo
st.logo(
    "https://cdn.prod.website-files.com/66cf2bfc3ed15b02da0ca770/66d07240057721394308addd_Logo%20(1).svg",
    link="https://www.crewai.com/",
    size="large"
)

#--------------------------------#
#         Streamlit Session State         #
#--------------------------------#
if "analyze_ready" not in st.session_state:
    st.session_state["analyze_ready"] = False

### PDF-File Handler

def process_pdf_file(file) -> str:
    """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    content_type = magic.from_buffer(file.read(1024), mime=True)
    file.seek(0)
    
    if content_type != "application/pdf":
        st.error("PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    contents = file.read()
    pdf = PyPDF2.PdfReader(io.BytesIO(contents))
    
    full_text = ""
    for page in pdf.pages:
        full_text += page.extract_text()
    
    return full_text

# Main layout
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.title("ğŸ” :red[CrewAI] Performance Analysis Assistant", anchor=False)


st.subheader("í´ë¼ì´ì–¸íŠ¸ ìš”êµ¬ì‚¬í•­ íŒŒì¼")
uploaded_file_client = st.file_uploader(
    "í´ë¼ì´ì–¸íŠ¸ ìš”êµ¬ì‚¬í•­ íŒŒì¼", accept_multiple_files=False
)
# if uploaded_file_client:
#     bytes_data = uploaded_file_client.read()
#     full_text = process_pdf_file(uploaded_file_client)
#     # st.write("file content:", full_text)
#     # st.write(bytes_data)

st.subheader("ì¸í„°ë·° ë‚´ìš© íŒŒì¼")
uploaded_file_interview = st.file_uploader(
    "ì¸í„°ë·° ë‚´ìš© íŒŒì¼", accept_multiple_files=False
)
# if uploaded_file_interview:
#     bytes_data = uploaded_file_interview.read()
#     full_text = process_pdf_file(uploaded_file_interview)
#     # st.write("file content:", full_text)
#     # st.write(bytes_data)


def analyze_files(client_file, interview_file):
    logger.info("Received analysis request")
    
    # try:
    # í´ë¼ì´ì–¸íŠ¸ íŒŒì¼ ì²˜ë¦¬
    client_content = process_pdf_file(client_file)
    client_prompt = CLIENT_REQUIREMENTS_PROMPT.format(text=client_content)
    client_analysis = get_chat_completion(client_prompt)
    
    # ì¸í„°ë·° íŒŒì¼ ì²˜ë¦¬
    interview_content = process_pdf_file(interview_file)
    interview_prompt = INTERVIEW_PROMPT.format(text=interview_content)
    interview_analysis = get_chat_completion(interview_prompt)
    
    return {
        "status": "success",
        "client_analysis": client_analysis,
        "interview_analysis": interview_analysis
    }
    
    # except Exception as e:
    #     logger.error(f"Analysis failed: {str(e)}", exc_info=True)
    #     raise HTTPException(status_code=500, detail=str(e))


bt_col1, bt_col2, bt_col3 = st.columns([1, 1, 1])
with bt_col2:
    button_analyze = st.button(label="ğŸ“ Summarize Documents", type="primary", use_container_width=True)

if button_analyze:
    col1, col2 = st.columns([1, 1])

#     client_content = """
# ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ë¶„ì„í•˜ì—¬ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

# 1. **í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ëª©í‘œ**
#    - ì„œë¹„ìŠ¤ì„¼í„° ì§ì›ë“¤ì˜ ì„œë¹„ìŠ¤ ì—­ëŸ‰ì„ ê°œì„ í•˜ê¸° ìœ„í•œ êµìœ¡ í”„ë¡œê·¸ë¨ ê°œë°œ.
#    - DE CS ë§ˆì¸ë“œë¥¼ íŠ¹íˆ ê°•í™”í•˜ì—¬ ê³ ê° ë§Œì¡±ë„ë¥¼ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨.

# 2. **ì£¼ìš” ìš”êµ¬ì‚¬í•­ ëª©ë¡**
#    - ì„œë¹„ìŠ¤ì„¼í„° ì§ì›ë“¤ì´ DE CS ë§ˆì¸ë“œë¥¼ ì´í•´í•˜ê³  ì ìš©í•  ìˆ˜ ìˆëŠ” êµìœ¡ ë‚´ìš© í¬í•¨.
#    - ê³ ê° ë§Œì¡±ë„ ì§€ìˆ˜ë¥¼ ë†’ì´ê¸° ìœ„í•œ ì‹¤ì§ˆì ì¸ ì„œë¹„ìŠ¤ ê¸°ìˆ  êµìœ¡ ì œê³µ.
#    - ì„œë¹„ìŠ¤ ê´€ë ¨ êµìœ¡ì˜ íš¨ê³¼ì„± í‰ê°€ë¥¼ ìœ„í•œ ê¸°ì¤€ ë§ˆë ¨.
#    - êµìœ¡ í”„ë¡œê·¸ë¨ì€ ëª¨ë“  ì„œë¹„ìŠ¤ì„¼í„° ì§ì›ì´ ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ ìœ ì—°í•œ í˜•íƒœë¡œ ì„¤ê³„.

# 3. **ì œì•½ì‚¬í•­ì´ë‚˜ íŠ¹ë³„ ê³ ë ¤ì‚¬í•­**
#    - ì„œë¹„ìŠ¤ì„¼í„° ì§ì›ë“¤ì€ ê°œë³„ ì‚¬ì—…ì ì†Œì†ì´ë¯€ë¡œ, êµìœ¡ í”„ë¡œê·¸ë¨ì´ ê° ì„¼í„°ì˜ ìš´ì˜ì— ì‹¤ì§ˆì ìœ¼ë¡œ ì ìš©ë  ìˆ˜ ìˆì–´ì•¼ í•¨.
#    - í˜„ì¬ ì œê³µëœ êµìœ¡ì˜ ë‚´ìš©ê³¼ í˜•ì‹ì´ ì§ì›ë“¤ì—ê²Œ ìœ ìš©í•œì§€ ê²€í†  í›„ ê°œì„  ë°©ì•ˆ ì œì‹œê°€ í•„ìš”.
#    - ê²½ìŸì‚¬ì™€ì˜ ë¹„êµ ë¶„ì„ì„ í†µí•´ ì°¨ë³„í™”ëœ êµìœ¡ í”„ë¡œê·¸ë¨ ê°œë°œì´ ìš”êµ¬ë¨.
#    - ì§ì›ì˜ ì„œë¹„ìŠ¤ í–¥ìƒì„ ìœ„í•´ ì‹¤ì‹œê°„ í”¼ë“œë°±ê³¼ í‰ê°€ í”„ë¡œê·¸ë¨ í•„ìš”.

# 4. **ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼ë¬¼**
#    - ê°œë°œëœ êµìœ¡ í”„ë¡œê·¸ë¨ê³¼ ë§¤ë‰´ì–¼: DE CS ë§ˆì¸ë“œ ê´€ë ¨ ìë£Œì™€ ì„œë¹„ìŠ¤ ê¸°ìˆ  í›ˆë ¨ ëª¨ë“ˆ í¬í•¨.
#    - êµìœ¡ íš¨ê³¼ í‰ê°€ ë¦¬í¬íŠ¸: êµìœ¡ í›„ ê³ ê° ë§Œì¡±ë„ ì§€ìˆ˜ ë³€í™” ë° ì§ì› í”¼ë“œë°± ê²°ê³¼ í¬í•¨.
#    - ê³ ê° ë§Œì¡±ë„ ì§€ìˆ˜ ê°œì„  ëª©í‘œ ìˆ˜ì¹˜ ë„ì¶œ ë° ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ì‹¤í–‰ ê³„íš. 

# ì´ì™€ ê°™ì€ ë¶„ì„ì„ í†µí•´ ìš”êµ¬ì‚¬í•­ì„ ëª…í™•íˆ íŒŒì•…í•˜ê³ , êµìœ¡ í”„ë¡œê·¸ë¨ ê°œë°œ ë°©í–¥ì„±ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# """

#     interview_content = """
# ### 1. ì¸í„°ë·° ëŒ€ìƒìì˜ ì£¼ìš” ê´€ì‹¬ì‚¬
# - **ê³ ê° í‰ê°€**: ê³ ê° í‰ê°€ê°€ ì„±ê³¼ê¸‰ê³¼ ì—°ê²°ë˜ì–´ ìˆì–´, ì—”ì§€ë‹ˆì–´ë“¤ì´ í‰ê°€ì— ëŒ€í•œ ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤. ê³ ê°ì˜ ì„±í–¥ íŒŒì•…ê³¼ ê³ ê° ì‘ëŒ€ ëŠ¥ë ¥ì´ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
# - **ê¸°ìˆ ê³¼ ì†Œí†µì˜ ê· í˜•**: ê¸°ìˆ ì ì¸ ëŠ¥ë ¥ ì™¸ì— ê³ ê° ì‘ëŒ€ë‚˜ ì†Œí†µ ëŠ¥ë ¥ì´ ë” ì¤‘ìš”í•˜ë‹¤ëŠ” ì¸ì‹ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ê¸°ìˆ ì„ ì˜ ì•Œê³ ë„ ê³ ê° ì§ˆë¬¸ì— ë‹¹í™©í•˜ëŠ” ì‚¬ë¡€ë¥¼ ì§€ì í•©ë‹ˆë‹¤.
# - **ì—…ë¬´ì˜ í¸ì°¨**: ë‹´ë‹¹í•˜ëŠ” ì œí’ˆì— ë”°ë¼ ì—…ë¬´ëŸ‰ì´ ë‹¬ë¼ì§€ë©°, ì´ëŠ” ì—”ì§€ë‹ˆì–´ì˜ ìˆ˜ì…ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ë„ ì£¼ìš” ê´€ì‹¬ì‚¬ì…ë‹ˆë‹¤.

# ### 2. íŒŒì•…ëœ ë¬¸ì œì ì´ë‚˜ ë‹ˆì¦ˆ
# - **ê³ ê° ì‘ëŒ€ ëŠ¥ë ¥ ë¶€ì¡±**: ì—”ì§€ë‹ˆì–´ë“¤ì´ ê³ ê° ì‘ëŒ€ ì‹œ í•„ìš”í•œ ê¸°ìˆ ì´ë‚˜ ì†Œí†µ ëŠ¥ë ¥ì´ ë¶€ì¡±í•œ ê²½ìš°ê°€ ë§ì•„, ë‚®ì€ í‰ê°€ë¥¼ ë°›ëŠ” ê²½ìš°ê°€ ë°œìƒí•©ë‹ˆë‹¤.
# - **êµìœ¡ì˜ ë¹„íš¨ìœ¨ì„±**: ê¸°ì¡´ ê³ ê° ì‘ëŒ€ êµìœ¡ì´ í˜„ì¥ ìƒí™©ì„ ë°˜ì˜í•˜ì§€ ëª»í•˜ê³ , ì—”ì§€ë‹ˆì–´ë“¤ì´ í˜•ì‹ì ìœ¼ë¡œ êµìœ¡ì„ ì´í–‰í•˜ì—¬ ì‹¤ì œ ìƒí™©ì— ì ìš©í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.
# - **ì‹ ì… êµìœ¡ ë¶€ì¡±**: ì‹ ì… ì—”ì§€ë‹ˆì–´ì— ëŒ€í•œ í˜„ì¥êµìœ¡ì´ ë¯¸ë¹„í•˜ì—¬, ì‹¤ë¬´ì— í•„ìš”í•œ ê¸°ìˆ  ìŠµë“ê³¼ ê³ ê° ì‘ëŒ€ ëŠ¥ë ¥ì´ ì œëŒ€ë¡œ ë°°ì–‘ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.
# - **ë‹¨ë°œì„± êµìœ¡ì˜ í•œê³„**: í˜„ì¬ ì§„í–‰ë˜ëŠ” êµìœ¡ì´ ì¼íšŒì„±ìœ¼ë¡œ, ì§€ì†ì ì´ê³  ë§ì¶¤í˜• êµìœ¡ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.

# ### 3. ì œì•ˆëœ í•´ê²°ë°©ì•ˆì´ë‚˜ ì•„ì´ë””ì–´
# - **ë§ì¶¤í˜• êµìœ¡ í•„ìš”ì„±**: ê°œì¸ë³„ ë¬¸ì œì (ì˜ˆ: ê³ ê° ì‘ëŒ€, ê¸°ìˆ  ë¬¸ì œ ë“±)ì„ íŒŒì•…í•˜ê³  ì½”ì¹­í•˜ì—¬ ë§ì¶¤í˜• êµìœ¡ì„ ì‹œí–‰í•´ì•¼ í•œë‹¤ëŠ” ì•„ì´ë””ì–´ê°€ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.
# - **í˜„ì¥ ê²½í—˜ ë°˜ì˜**: ì‹¤ì œ í˜„ì¥ì˜ ì–´ë ¤ì›€ê³¼ ê²½í—˜ìë“¤ì˜ ì˜ê²¬ì„ ë°˜ì˜í•˜ì—¬ êµìœ¡ í”„ë¡œê·¸ë¨ì„ ê°œì„ í•´ì•¼ í•œë‹¤ëŠ” í•„ìš”ì„±ì´ ìˆìŠµë‹ˆë‹¤.
# - **ì§€ì†ì ì¸ í‰ê°€ ë° í”¼ë“œë°±**: êµìœ¡ì´ ëë‚œ í›„ì—ë„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ì†ì ìœ¼ë¡œ ì—”ì§€ë‹ˆì–´ì˜ ì„±ê³¼ë¥¼ ê´€ë¦¬í•˜ê³  í‰ê°€í•´ì•¼ í•˜ë©°, ì •ê¸°ì ìœ¼ë¡œ ì½”ì¹­ì„ í•´ì•¼ í•œë‹¤ëŠ” ì œì•ˆì´ ìˆìŠµë‹ˆë‹¤.
# - **ë¡¤í”Œë ˆì‰ê³¼ ìƒí™©ë³„ í›ˆë ¨ ê°•í™”**: ë¡¤í”Œë ˆì‰ì„ í†µí•œ ê³ ê° ì‘ëŒ€ êµìœ¡ì„ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê³ , ì‹¤ì œ ê³ ê° ìƒí™©ì— ë§ì¶˜ í›ˆë ¨ ë°©ì‹ìœ¼ë¡œ ê°œì„ í•´ì•¼ í•œë‹¤ê³  ì–¸ê¸‰ë˜ì—ˆìŠµë‹ˆë‹¤.

# ### 4. ì¶”ê°€ ê³ ë ¤ì‚¬í•­ì´ë‚˜ í”¼ë“œë°±
# - **ì—…ë¬´ê³¼ëŸ‰**: ì—”ì§€ë‹ˆì–´ë“¤ì´ ë§Œë‚˜ëŠ” ê³ ê° ìˆ˜ê°€ ë§ê³ , í•œ ë²ˆì— ì—¬ëŸ¬ ê¸°ê³„ë¥¼ ìˆ˜ë¦¬í•´ì•¼ í•˜ê¸°ì— ì¼ì •í•œ ì—…ë¬´ ë°°ë¶„ì´ ì–´ë ¤ì›Œ íš¨ìœ¨ì„±ì´ ë–¨ì–´ì§€ëŠ” ì¸¡ë©´ë„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ê°œì„  ë°©ì•ˆë„ í•„ìš”í•©ë‹ˆë‹¤.
# - **ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬**: ê³ ê° í‰ê°€ë¡œ ì¸í•œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì¤„ì´ê¸° ìœ„í•´, ê¸ì •ì ì¸ í‰ê°€ ì‹œìŠ¤í…œ ë˜ëŠ” íŒ€ì›Œí¬ ì¤‘ì‹¬ì˜ ë¬¸í™” í˜•ì„±ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# - **ê³„ì†ì ì¸ êµìœ¡ê³¼ ì—…ë°ì´íŠ¸**: êµìœ¡ ë‚´ìš©ì€ ì‹¤ì œ ë³€í™”í•˜ëŠ” í˜„ì¥ í™˜ê²½ì´ë‚˜ ê¸°ìˆ  ë°œì „ì— ë§ì¶”ì–´ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì–´ì•¼ í•˜ëŠ” ì‚¬í•­ë„ ê°•ì¡°í•´ì•¼ í•©ë‹ˆë‹¤.
# """

    if uploaded_file_client and uploaded_file_interview:
        with st.status("Processing data...", expanded=True) as status:
            results = analyze_files(uploaded_file_client, uploaded_file_interview)
            status.update(
                label="Process complete!", state="complete", expanded=False
            )
            with col1.container():
                st.markdown("### <í´ë¼ì´ì–¸íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„>")
                # st.write(client_content)
                # st.session_state["client_analysis"] = client_content
                st.write(results["client_analysis"])
                st.session_state["client_analysis"] = results["client_analysis"]
            with col2.container():
                st.markdown("### <ì¸í„°ë·° í•µì‹¬ ë‚´ìš© ì •ë¦¬>")
                # st.write(interview_content)
                # st.session_state["interview_analysis"] = interview_content
                st.write(results["interview_analysis"])
                st.session_state["interview_analysis"] = results["interview_analysis"]
            
            st.session_state["analyze_ready"] = True


# Render sidebar and get selection (provider and model)
selection = render_sidebar()

# Check if API keys are set based on provider
if selection["provider"] == "OpenAI":
    if not os.environ.get("OPENAI_API_KEY"):
        st.warning("âš ï¸ Please enter your OpenAI API key in the sidebar to get started")
        st.stop()
elif selection["provider"] == "GROQ":
    if not os.environ.get("GROQ_API_KEY"):
        st.warning("âš ï¸ Please enter your GROQ API key in the sidebar to get started")
        st.stop()

# Check EXA key for non-Ollama providers
if selection["provider"] != "Ollama":
    if not os.environ.get("EXA_API_KEY"):
        st.warning("âš ï¸ Please enter your EXA API key in the sidebar to get started")
        st.stop()

# Add Ollama check
if selection["provider"] == "Ollama" and not selection["model"]:
    st.warning("âš ï¸ No Ollama models found. Please make sure Ollama is running and you have models loaded.")
    st.stop()

# Create two columns for the input section
# input_col1, input_col2, input_col3 = st.columns([1, 3, 1])
# with input_col2:
#     task_description = st.text_area(
#         "What would you like to research?",
#         value="Research the latest AI Agent news in February 2025 and summarize each.",
#         height=68
#     )

# Convert Markdown to DOCX using a temporary file
# def convert_md_to_docx(md_text):
#     with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmpfile:
#         pypandoc.convert_text(md_text, "docx", format="md", outputfile=tmpfile.name)
#         tmpfile_path = tmpfile.name

#     # Read the DOCX file into memory
#     with open(tmpfile_path, "rb") as docx_file:
#         docx_data = docx_file.read()

#     return docx_data

if st.session_state["analyze_ready"]:
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        start_research = st.button("ğŸš€ Start Analysis", use_container_width=True, type="primary")

    if start_research:

        with st.status("ğŸ¤– **Agents at work...**", state="running", expanded=True) as status:
            try:
                with st.container(height=500, border=False):
                    sys.stdout = StreamToExpander(st)
                    crew = GapAnalysisCrew(
                        client_analysis=st.session_state["client_analysis"],
                        interview_analysis=st.session_state["interview_analysis"]
                    )

                    final_report = crew.analyze(
                        st.session_state["client_analysis"],
                        st.session_state["interview_analysis"],
                    )
                status.update(label="âœ… Analysis completed!", state="complete", expanded=False)

            except Exception as e:
                status.update(label="âŒ Error occurred", state="error")
                st.error(f"An error occurred: {str(e)}")
                st.stop()

        # final_report = """# Research Report

        #     ## Introduction
        #     This is an automatically generated research report.

        #     ## Findings
        #     - Finding 1: Important discovery.
        #     - Finding 2: Another key insight.

        #     ## Conclusion
        #     The research indicates that...
        #     """
        
        # Convert CrewOutput to string for display and download
        result_text = str(final_report)
        
        # # Convert Markdown to DOCX
        # docx_data = convert_md_to_docx(result_text)
        
        # Display the final result
        st.markdown(result_text)

        # Create download buttons
        st.divider()
        download_col1, download_col2, download_col3 = st.columns([1, 2, 1])
        with download_col2:
            st.markdown("### ğŸ“¥ Download Research Report")

            # Download as Markdown
            st.download_button(
                label="Download Report as Mardown",
                data=result_text,
                file_name="research_report.md",
                mime="text/markdown",
                help="Download the research report in Markdown format"
            )

            # # Download as DOCX
            # st.download_button(
            #     label="Download as DOCX",
            #     data=docx_data,
            #     file_name="research_report.docx",
            #     mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            #     help="Download the research report in Word format"
            # )

            st.session_state["analyze_ready"] = False

        # Renew previous process
        st.session_state["analyze_ready"] = False

# Add footer
st.divider()
footer_col1, footer_col2, footer_col3 = st.columns([1, 2, 1])
with footer_col2:
    st.caption("Made with â¤ï¸ using [CrewAI](https://crewai.com), [Exa](https://exa.ai) and [Streamlit](https://streamlit.io)")
